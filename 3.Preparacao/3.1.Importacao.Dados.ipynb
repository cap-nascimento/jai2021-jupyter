{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importar Bibliotecas \n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que j√° conhecemos um pouco sobre as principais estruturas do Pandas (*Series e Dataframes*), agora √© a vez de aprender a como **importar dados** para tais estruturas.\n",
    "\n",
    "> Embora a cria√ß√£o de estruturas de dados de forma manual seja √∫til para determinadas aplica√ß√µes ou at√© mesmo para r√°pidos testes e valida√ß√µes, na pr√°tica, a nossa fonte de üé≤üé≤ normalmente ser√° via enormes arquivos!\n",
    "\n",
    "Em ci√™ncia de dados, muitos projetos obrigam seus cientistas a reunir uma miscel√¢nea de padr√µes de fontes de dados, tais como **CSV**, **TSV**, **XLS**, **JSON**, ou outro formato. Assim, √© crucial saber lidar com os principais formatos de dados em Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos Texto - CSV\n",
    "\n",
    "Um dos formatos **mais utilizados** √© o CSV, que nada mais s√£o que arquivos de texto **separados por v√≠rgulas**. A figura abaixo mostra um arquivo CSV.\n",
    "\n",
    "![Exemplo de Arquivo CSV](./img/CSV.png)\n",
    "\n",
    "> **Como importar importar arquivos CSV utilizando o pandas?** ü§î\n",
    "\n",
    "Simples! Basta segui os comandos abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spotify_Charts_df = pd.read_csv('./datasets/spotify_charts_complete.csv', sep=',')\n",
    "spotify_Charts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "\n",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro na Linha 46: ‚ùå\n",
    "\n",
    "\n",
    "Note que n√≥s temos **seis** colunas do arquivo de entrada: \n",
    "- chart_week\n",
    "- position\n",
    "- track_name\n",
    "- artist\n",
    "- streams\n",
    "- song_id\n",
    "\n",
    "> **Como o Pandas est√° enxergando a linha: 46** üîé\n",
    "\n",
    " _2020-01-02$\\color{#ff0000}{,}$45$\\color{#ff0000}{,}$10$\\color{#ff0000}{,}$**000 Hours (with Justin Bieber)**$\\color{#ff0000}{,}$Dan + Shay$\\color{#ff0000}{,}$10360035$\\color{#ff0000}{,}$2wrJq5XKLnmhRXHIAf9xBa_\n",
    "\n",
    "> **Como o Pandas deveria enxergar:** üëÄ\n",
    "\n",
    " _2020-01-02$\\color{#ff0000}{,}$45$\\color{#ff0000}{,}$**10,000 Hours (with Justin Bieber)**$\\color{#ff0000}{,}$Dan + Shay$\\color{#ff0000}{,}$10360035$\\color{#ff0000}{,}$2wrJq5XKLnmhRXHIAf9xBa_\n",
    " \n",
    "Erro de **tokeniza√ß√£o** √© um problema muito comum quando lidamos com arquivos CSV. \n",
    "\n",
    "> **Como resolver esse problema?** ü§î\n",
    "\n",
    "Neste caso, para que esse tipo de erro seja evitado, ter√≠amos que **escapar todas as Strings usando aspas (')**. Desta forma, todas as v√≠rgulas de campos textuais n√£o ser√£o consideradas como separador de campo. Ou seja, todas as linhas do arquivo deveriam se parecer com:\n",
    "\n",
    "_'2020-01-02',45,**'10,000 Hours (with Justin Bieber)'**,**'Dan + Shay'**,10360035,2wrJq5XKLnmhRXHIAf9xBa_\n",
    "\n",
    "> Embora n√£o seja necess√°rio, √© comum que todos os campos de arquivos CSVs sejam escapados por aspas, n√£o se limitando apenas aos campos textuais! ü§ì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leitura sem erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_Charts_df = pd.read_csv('./datasets/spotify_charts_complete_Line45.csv', sep=',')\n",
    "spotify_Charts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos Texto - TSV\n",
    "\n",
    "Uma alternativa aos arquivos CSV, s√£o os arquivos TSV (valores separados por tabula√ß√£o). Neste tipo de arquivo, como o delimitador de campo √© uma **tabula√ß√£o**, n√£o deparamos com o problema de tokeniza√ß√£o. \n",
    "\n",
    "A figura abaixo mostra um arquivo TSV.\n",
    "\n",
    "![Exemplo de Arquivo TSV](./img/TSV.png)\n",
    "\n",
    " A leitura deste tipo de arquivo √© feita utilizando a mesma fun√ß√£o **read_csv**. No entanto, precisamos especificar que o separador √© a tabula√ß√£o (\\t). \n",
    " \n",
    " > ‚ö†Ô∏è Se n√£o for especificado o delimitador, o python retornar√° um erro de **Parser**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_Charts_df = pd.read_csv('./datasets/spotify_charts_complete.tsv', sep='\\t')\n",
    "spotify_Charts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üí° Uma fun√ß√£o alternativa para a leitura de arquivos deste tipo √© a **read_table()**\n",
    "\n",
    "Neste caso, n√£o √© necess√°rio o uso de outros par√¢metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fun√ß√£o read_table √© utilizada para ler arquivos .tsv\n",
    "charts = pd.read_table('./datasets/spotify_charts_complete.tsv')\n",
    "charts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos de Planilhas - XLS\n",
    "\n",
    "Outro formato bastante popular s√£o os arquivos que j√° se encontram em estrutura tabulares, tais como arquivos do Microsoft Excel. A figura abaixo mostra um arquivo XLS.\n",
    "\n",
    "![Exemplo de Arquivo XLS](./img/XLSX.png)\n",
    "\n",
    "O pandas possui a fun√ß√£o **read_excel(‚Äòarquivo.xlsx‚Äô)** para efetuar a leitura de arquivos em formato de planilhas eletr√¥nicas.\n",
    "\n",
    "> ‚ö†Ô∏è Para a importa√ß√£o de uma **planilha espec√≠fica** em um mesmo arquivo (uma **aba**), √© preciso utilizar o par√¢metro **sheet_name**.\n",
    "\n",
    "Na figura acima, o arquivo chamado ‚Äòdados.xlsx‚Äô possui duas abas: _**spotify_artists**_ e _**spotify_charts**_. \n",
    "\n",
    "Para importar apenas o conte√∫do da segunda aba (**spotify_charts**) do arquivo dados.xlsx, programa-se: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_charts = pd.read_excel ('./datasets/dados.xlsx', sheet_name='spotify_charts')\n",
    "spotify_charts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è Caso o `sheet_name` n√£o seja especificado, importa-se a primeira aba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_artists = pd.read_excel ('./datasets/dados.xlsx')\n",
    "spotify_artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos JSON (JavaScript Object Notation)\n",
    "\n",
    "Um arquivo JSON armazena estruturas de dados simples, al√©m de serem leves, textuais, leg√≠veis por humanos e edit√°veis com editor de texto. Arquivos JSON representam dados com o conceito de chave e valor:\n",
    "\n",
    "cada valor tem uma chave que descreve seu significado. Por exemplo, o par de _**chave:valor**_ **name:‚ÄòMichael Jackson‚Äô** representa o artista ‚ÄòMichael Jackson‚Äô. A figura abaixo mostra um trecho de um arquivo JSON.\n",
    "\n",
    "![Exemplo de Arquivo JSON](./img/JSON.png)\n",
    "\n",
    "> üí°  Note que √© poss√≠vel compreender os dados, e alter√°-los utilizando um editor de texto.\n",
    "\n",
    "\n",
    "Para importar arquivos JSON, o pandas tem a fun√ß√£o **read_json()**, com funcionamento similar √†s anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks = pd.read_json('./datasets/Michael_Jackson_tracks.json')\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, a sa√≠da acima parece um pouco desajeitada, certo? ü§î\n",
    "\n",
    "Isso acontece pois este √© um arquivo **JSON aninhado**, ou seja, ele possui v√°rios n√≠veis de pares [chave:valor]. \n",
    "\n",
    "O primeiro n√≠vel √© a chave _**tracks**_, ou seja, cada linha do dataframe retornado √© um valor para 'track'. Neste caso, n√£o √© poss√≠vel transformar um arquivo JSON __aninhado__ diretamente em um dataframe, pois a fun√ß√£o __*read_json*__ faz a leitura de strings JSON mais simples.\n",
    "\n",
    "Para o nosso exemplo, a obten√ß√£o de um dataframe organizado demanda a divis√£o deste JSON aninhado. Para isso, a fun√ß√£o *__json_normalize()__* √© utilizada para ler a __STRING__ JSON aninhada e devolver um DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Precisamos importar a biblioteca JSON\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primeiro Passo:\n",
    "ler a string JSON com a fun√ß√£o **json.loads()** da biblioteca JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/Michael_Jackson_tracks.json','r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segundo Passo: \n",
    "\n",
    "Passamos o objeto JSON (data) para a fun√ß√£o **json_normalize()** que retornar√° um DataFrame contendo os dados necess√°rios. Para isso, √© preciso informar o primeiro n√≠vel de chave (_tracks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.json_normalize(data['tracks'])\n",
    "\n",
    "tracks_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna __*artists*__ tamb√©m √© composta por mais um n√≠vel do arquivo json. \n",
    "\n",
    "Para melhor visualizar esta coluna, √© preciso repetir o processo acima construindo um novo dataframe, no entanto √© preciso informar a linha que se deseja recuperar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = pd.json_normalize(data['tracks'][0]['artists'])\n",
    "\n",
    "artist_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros formatos\n",
    "\n",
    "Al√©m desses formatos, √© poss√≠vel carregar dados de XML e de bancos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'TJSE')\n",
      "(2, 'TRIBUNAL DE JUSTICA DO ESTADO DE GOIAS')\n",
      "(3, 'TJPR')\n",
      "(4, 'TRIBUNAL DE JUSTI√áA DO ESTADO DE MATO GROSSO')\n",
      "(5, 'TJ-TO')\n",
      "(6, 'JFTO')\n",
      "(7, 'JFMG')\n",
      "(8, 'Poder Judici√°rio do RN')\n",
      "(9, 'TRIBUNAL DE JUSTI√áA DO ESTADO DO PIAU√ç')\n",
      "(10, 'TRIBUNAL DE JUSTICA DO ESTADO DO CEARA')\n"
     ]
    }
   ],
   "source": [
    "# Primeiro, importa o driver para o MySQL\n",
    "import mysql.connector\n",
    "\n",
    "# O seguinte c√≥digo faz a conex√£o:\n",
    "conn = mysql.connector.connect(user='jai',              # Seu User\n",
    "                                password='senha',       # Sua senha\n",
    "                                host='127.0.0.1',       # Endere√ßo do servidor\n",
    "                                database='jusbd')       # Base de Dados\n",
    "\n",
    "# Criar um cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Elabora uma consulta\n",
    "query = (\"SELECT * from org√£o limit 10\")\n",
    "\n",
    "# Executa a consulta\n",
    "cursor.execute(query)\n",
    "\n",
    "# Exibe o resultado da consulta\n",
    "for l in cursor.fetchall():\n",
    "    print(l)\n",
    "\n",
    "# Fecha o cursor\n",
    "cursor.close()\n",
    "# Fecha a conex√£o\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook apresentou como importar dados de diversos formatos para o pandas.\n",
    "\n",
    "> üîé **Se interessou?** D√™ uma olhada na documenta√ß√£o da biblioteca *pandas* para informa√ß√µes extras sobre leitura de dados:\n",
    "[IO Tools](https://pandas.pydata.org/docs/user_guide/io.html)\n",
    "\n",
    "---\n",
    "\n",
    "O pr√≥ximo notebook ([3.2.Limpeza.ipynb](3.2.Limpeza.ipynb)) apresenta como fazer a limpeza dos dados."
   ]
  }
 ],
 "metadata": {
  "julynter-results": {
   "filteredId": [],
   "filteredIndividual": [],
   "filteredRestart": [],
   "filteredType": [],
   "hash": "6b27a9fb782d43d181404925077b28607a688e69",
   "visible": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
