{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação de Dados\n",
    "\n",
    "Anteriormente, vimos como podemos combinar dados de diferentes fontes em um DataFrame unificado. Em geral, após um processo de Integração de dados, colunas com diferentes tipos de dados podem ser geradas. Na Transformação de dados, o principal objetivo é exatamente transformar os dados de diferentes formatos em um formato suportado por modelos de Aprendizado de Máquina. A Transformação de dados possui algumas etapas em comum com a Limpeza de dados, incluindo técnicas de remoção de ruído e discretização de dados. Assim, a seguir, apresentamos as demais etapas envolvidas nesta fase de Pré-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os pacotes necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "pd.set_option('display.max_columns', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados não padronizados\n",
    "\n",
    "Ter dados coletados de diferentes fontes pode gerar um conjunto de dados heterogêneo e não padronizado, contendo atributos de diferentes escalas. O reescalonamento de dados não é uma etapa obrigatória, mas definitivamente é uma boa prática. Muitos métodos de Aprendizado de Máquina são mais eficazes se os atributos dos dados seguem um padrão. Portanto, para garantir que o desempenho de nossos modelos não varie por causa de diferentes magnitudes de recursos, precisamos realizar o reescalonamento de dados. Essencialmente, existem duas técnicas de reescalonamento de dados, que transformam as features para que fiquem em uma mesma escala, magnitude ou intervalo. A seguir, descrevemos e exemplificamos cada uma delas utilizando o conjunto de atributos numéricos que descrem as músicas do Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['popularity' 'track_number' 'num_artists' 'num_available_markets'\n",
      " 'duration_ms' 'key' 'mode' 'time_signature' 'acousticness' 'danceability'\n",
      " 'energy' 'instrumentalness' 'liveness' 'loudness' 'speechiness' 'valence'\n",
      " 'tempo']\n"
     ]
    }
   ],
   "source": [
    "# Lendo os dados\n",
    "data = pd.read_table('../dataset/spotify_hits_dataset_complete.tsv', encoding='utf-8')\n",
    "\n",
    "# Selecionando apenas variáveis numéricas\n",
    "df = data.select_dtypes(include=['number'])\n",
    "print(df.columns.values) # imprime as colunas restantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização de dados \n",
    "\n",
    "Reescalona os atributos numéricos em um intervalo de 0 a 1. Em resumo, o objetivo da normalização é alterar os valores das colunas numéricas no conjunto de dados para uma escala comum, sem distorcer as diferenças nos intervalos de valores. O exemplo a seguir demonstra a normalização de dados, redimensionando cada atributo do *DataFrame* para um intervalo de $[0,1]$. Para isso, subtraímos o valor mínimo de cada coluna e dividimos pelo intervalo, aplicando e escala min-max do *Pandas* usando os métodos `min()` e `max()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>track_number</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>...</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>0.212314</td>\n",
       "      <td>0.506887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176348</td>\n",
       "      <td>0.558386</td>\n",
       "      <td>0.606828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243727</td>\n",
       "      <td>0.143312</td>\n",
       "      <td>0.393380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  track_number  num_artists  ...  speechiness   valence     tempo\n",
       "0    0.793814      0.310345          0.0  ...     0.015335  0.212314  0.506887\n",
       "1    0.680412      0.448276          0.0  ...     0.176348  0.558386  0.606828\n",
       "2    0.134021      0.000000          0.0  ...     0.243727  0.143312  0.393380\n",
       "\n",
       "[3 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = df.copy()  # cópia do DataFrame\n",
    "for coluna in df_norm.columns:  # Para cada coluna,\n",
    "    df_norm[coluna] = (  # Normalização min-max\n",
    "        df_norm[coluna] - df_norm[coluna].min()\n",
    "    ) / (df_norm[coluna].max() - df_norm[coluna].min())\n",
    "df_norm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### Padronização de Dados\n",
    "\n",
    "Reescalona a distribuição de cada atributo para apresentar média igual a zero e um desvio padrão igual a um. Em resumo, cada valor padronizado é calculado subtraindo a média do recurso correspondente e dividindo pelo desvio padrão. O exemplo a seguir demonstra a padronização de dados, transformando os atributos do *DataFrame* em distribuições com uma média igual a 0 e um desvio padrão igual a 1. Para isso, subtraímos a média de cada coluna e dividimos pelo desvio padrão, usando os métodos `mean()` e `std()` do *Pandas*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>track_number</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>...</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448125</td>\n",
       "      <td>1.007112</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802165</td>\n",
       "      <td>-1.217354</td>\n",
       "      <td>0.122480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.164943</td>\n",
       "      <td>1.806576</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462704</td>\n",
       "      <td>0.221431</td>\n",
       "      <td>0.658761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.118819</td>\n",
       "      <td>-0.791681</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992015</td>\n",
       "      <td>-1.504228</td>\n",
       "      <td>-0.486598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  track_number  num_artists  ...  speechiness   valence     tempo\n",
       "0    0.448125      1.007112    -0.644346  ...    -0.802165 -1.217354  0.122480\n",
       "1   -0.164943      1.806576    -0.644346  ...     0.462704  0.221431  0.658761\n",
       "2   -3.118819     -0.791681    -0.644346  ...     0.992015 -1.504228 -0.486598\n",
       "\n",
       "[3 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_padron = df.copy()  # cópia do DataFrame\n",
    "for coluna in df_padron.columns:  # Para cada coluna,\n",
    "    df_padron[coluna] = (  # Padronização\n",
    "        df_padron[coluna] - df_padron[coluna].mean()\n",
    "    ) / (df_padron[coluna].std())\n",
    "df_padron.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering (Engenharia de features)\n",
    "\n",
    "Consiste em criar ou remover features em um conjunto de dados procurando melhorar o desempenho dos modelos de Aprendizado de Máquina. Muitas das técnicas de Transformação e Limpeza de dados podem ser consideradas técnicas de Feature Engineering, incluindo métodos de reescalonamento, discretização e redução de dimensionalidade. Portanto, a seguir, cobrimos duas técnicas ainda não abordadas neste capítulo. Primeiro, criamos atributos a partir de dados categóricos e, em seguida, a partir de datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explicit</th>\n",
       "      <th>song_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Solo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Solo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Solo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Solo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Collaboration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  explicit      song_type\n",
       "0    False           Solo\n",
       "1     True           Solo\n",
       "2    False           Solo\n",
       "3    False           Solo\n",
       "4     True  Collaboration"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando apenas variáveis não-numéricas\n",
    "df = data[['explicit', 'song_type']].astype('category')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "explicit     category\n",
       "song_type    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retornando os dtypes do DataFrame\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados categóricos\n",
    "\n",
    "São variáveis que só podem assumir um número limitado e, geralmente, fixo de valores possíveis. Por exemplo, em nosso conjunto de músicas do Spotify, encontramos dados categóricos sobre o tipo e a expliciticidade das músicas. Ou seja, cada unidade de observação (i.e., música) é atribuída a um determinado grupo ou categoria nominal. Apesar de estarem frequentemente presentes em conjuntos de dados reais, a maioria dos algoritmos de Aprendizado de Máquina tem dificuldade para lidar com dados categóricos. Portanto, é preciso convertê-los em formas numéricas antes de serem usados. Uma das abordagens mais simples e comuns é converter variáveis categóricas em *dummies* ou indicadores. Para isso, podemos utilizar a função `get_dummies()` do *Pandas*, conforme o exemplo a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_style": "center",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explicit_False</th>\n",
       "      <th>explicit_True</th>\n",
       "      <th>song_type_Collaboration</th>\n",
       "      <th>song_type_Solo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   explicit_False  explicit_True  song_type_Collaboration  song_type_Solo\n",
       "0               1              0                        0               1\n",
       "1               0              1                        0               1\n",
       "2               1              0                        0               1\n",
       "3               1              0                        0               1\n",
       "4               0              1                        1               0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertendo em dummies\n",
    "df_dummies = pd.get_dummies(df)\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "explicit_False             uint8\n",
       "explicit_True              uint8\n",
       "song_type_Collaboration    uint8\n",
       "song_type_Solo             uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis de data\n",
    "\n",
    "São um tipo especial de dados categóricos. Embora, aparentemente, uma data nos forneça nada mais do que um momento específico no calendário, quando pré-processada corretamente, ela pode enriquecer muito o conjunto de dados. Nos exemplos a seguir, convertemos datas em formatos amigáveis, extraindo recursos e criando novas variáveis que podem ser usadas na análise de um modelo. Especificamente, extraímos recursos da data de lançamento das músicas do Spotify, utilizando métodos do *Pandas*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "cols = ['song_id', 'song_name', 'release_date']\n",
    "data = pd.read_table('../dataset/spotify_hits_dataset_complete.tsv', encoding='utf-8', usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_id                 object\n",
       "song_name               object\n",
       "release_date    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertendo a data de lançamento em 'datetime'\n",
    "data['release_date'] = pd.to_datetime(\n",
    "    data['release_date'])\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2rRJrJEo19S2J82BDsQ3F7</td>\n",
       "      <td>Falling</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3BYIzNZ3t9lRQCACXSMLrT</td>\n",
       "      <td>Venetia</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1g3J9W88hTG173ySZR6E9S</td>\n",
       "      <td>Tilidin Weg</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  song_id    song_name release_date  day  month  year\n",
       "0  2rRJrJEo19S2J82BDsQ3F7      Falling   2020-03-26   26      3  2020\n",
       "1  3BYIzNZ3t9lRQCACXSMLrT      Venetia   2020-03-06    6      3  2020\n",
       "2  1g3J9W88hTG173ySZR6E9S  Tilidin Weg   2020-07-30   30      7  2020"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['day'] = data['release_date'].dt.day  # dia\n",
    "data['month'] = data['release_date'].dt.month  # mês\n",
    "data['year'] = data['release_date'].dt.year  # ano\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados desbalanceados\n",
    "\n",
    "São uma ocorrência muito comum em domínios do mundo real, especialmente em modelos de classificação. Pode-se dizer que dados estão desbalanceados quando existe uma proporção desproporcional de observações de cada classe. Os impactos de dados desbalanceados não geram um erro imediato ao construir e executar seu modelo. Porém, os resultados podem ser ilusórios, dado que a maioria das técnicas de Aprendizado de Máquina funcionam melhor quando o número de amostras em cada classe é equilibrado. No exemplo a seguir, nós usamos as features acústicas das músicas do Spotify para prever se uma música é uma colaboração ou não. Especificamente, modelamos o problema como uma classificação binária, cada música é setada como 1 se a for uma colaboração, ou 0 caso contrário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'duration_ms', 'key', 'mode', 'time_signature', 'acousticness',\n",
    "    'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness',\n",
    "    'speechiness', 'valence', 'tempo', 'song_type'\n",
    "]\n",
    "\n",
    "# Selecionando algumas colunas do conjunto de músicas\n",
    "data = pd.read_table('../dataset/spotify_hits_dataset_complete.tsv', encoding='utf-8', usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_type</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solo</td>\n",
       "      <td>159381</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.236</td>\n",
       "      <td>127.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Solo</td>\n",
       "      <td>188800</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.562</td>\n",
       "      <td>142.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Solo</td>\n",
       "      <td>180950</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.171</td>\n",
       "      <td>109.090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  song_type  duration_ms  key  ...  speechiness  valence    tempo\n",
       "0      Solo       159381   10  ...       0.0364    0.236  127.087\n",
       "1      Solo       188800    9  ...       0.1750    0.562  142.933\n",
       "2      Solo       180950   10  ...       0.2330    0.171  109.090\n",
       "\n",
       "[3 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    752\n",
       "1    532\n",
       "Name: song_type, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['song_type'] = [ # Mapeia 'song_type' em 0 e 1\n",
    "    int(x == 'Collaboration') for x in data.song_type] \n",
    "data['song_type'].value_counts() # qtd de cada classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `value_counts()` computa os valores únicos de cada classe. Como resultado, apenas cerca de 41,4% das observações (i.e., 532 músicas) são colaborações. Portanto, se desejamos prever sempre a classe 0, músicas solo, obteríamos uma precisão de 58,6%. A seguir, nós testamos esse cenário criando um modelo linear de regressão logística, usando o módulo `sklearn.linear_model` e a classe `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5856697819314641\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = data.song_type # treino (X)\n",
    "X = data.drop('song_type', axis=1) # teste (y)\n",
    "logr = LogisticRegression().fit(X, y) # treinando o modelo de regressão logística\n",
    "pred_y_0 = logr.predict(X)\n",
    "print(accuracy_score(pred_y_0, y)) # acurácia do modelo\n",
    "print(np.unique(pred_y_0)) # classes previstas pelo modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado anterior indica que nosso modelo apresentou uma precisão geral de 58,6%. Ou seja, como consequência dos dados desbalanceados, nosso modelo prevê apenas uma classe. Isso significa que o modelo ignora completamente a classe minoritária (i.e., colaborações) em favor da classe majoritária (i.e., músicas solo). A seguir, aplicamos a técnica de *Downsampling*, que remove aleatoriamente observações da classe majoritária para evitar que seu sinal domine o algoritmo de aprendizagem. Primeiro, separamos as observações de cada classe em diferentes *DataFrames*. Em seguida, reamostramos a classe majoritária sem substituição, definindo o número de amostras para corresponder ao da classe minoritária. Finalmente, concatenamos o *DataFrame* da classe minoritária com o *DataFrame* resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    532\n",
       "0    532\n",
       "Name: song_type, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_majority = data[data.song_type == 0] # classe majoritária\n",
    "df_minority = data[data.song_type == 1] # classe minoritária\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority, replace=False,  # amostra sem substituição\n",
    "    n_samples=532,  # para corresponder à classe minoritária\n",
    "    random_state=123)  # garantindo reprodutibilidade\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "df_downsampled.song_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta vez, apesar do novo *DataFrame* ter menos observações do que o original, a proporção das duas classes agora está balanceada. Podemos, então, treinar novamente nosso modelo de regressão logística. Conforme o exemplo a seguir, após o balanceamento dos dados, o modelo deixa de prever apenas uma classe. Embora a precisão tenha diminuído, a métrica de avaliação se torna mais significativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.49154135338345867\n"
     ]
    }
   ],
   "source": [
    "y = df_downsampled.song_type # treino (X)\n",
    "X = df_downsampled.drop('song_type', axis=1) # teste (y)\n",
    "logr = LogisticRegression().fit(X, y) # Treinando o modelo de regressão logística\n",
    "pred_y_1 = logr.predict(X)\n",
    "print(np.unique(pred_y_1)) # acurácia do modelo\n",
    "print(accuracy_score(y, pred_y_1)) #classes previstas pelo modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Este notebook apresentou como fazer a transformação de dados de diferentes formatos.\n",
    "\n",
    "O próximo notebook ([3.4.Reducao.ipynb](3.4.Reducao.ipynb)) apresenta como aplicar técnicas de redução de dados para auxiliar a análise de dados com alta dimensionalidade."
   ]
  }
 ],
 "metadata": {
  "julynter-results": {
   "filteredId": [],
   "filteredIndividual": [],
   "filteredRestart": [],
   "filteredType": [],
   "hash": "5262264cd9b5bca8895a3c3c49a809815b06710a",
   "visible": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
